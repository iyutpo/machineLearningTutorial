{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cost Function\n",
    "$J(\\theta) = -\\frac{1}{m}\\sum^m_{i-1}[y^{(i)}log(h(x^{(i)}))+(1-y^{(i)})log(1-h(x^{(i)}))]$\n",
    "\n",
    "where $h(x) = \\frac{1}{1+e^{-\\theta x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(theta, x_i):\n",
    "    return 1 / (1 + math.exp(-theta * x_i))\n",
    "\n",
    "# def calculate_cost_function(x, y, theta, lamda):\n",
    "#     cost, m = 0, len(x)\n",
    "#     for i in range(m):\n",
    "#         cost = cost - 1/m * y[i] * np.log(h(x)) + (1 - y[i]) * np.log(1 - h(x[i])) + lamda/(2*m) * theta**2\n",
    "#     return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Algorithm\n",
    "$\\theta_j := \\theta_j - \\alpha \\frac{\\partial{J}}{\\partial{\\theta_j}}$\n",
    "\n",
    "$\\frac{\\partial{(J(\\theta))}}{\\partial{(\\theta_j)}} = -\\frac{1}{m}\\sum^m_{i=1}[y^{(i)}\\frac{1}{h(x)}\\frac{\\partial{h(x^{(i)})}}{\\partial{\\theta_j}}] + \\sum^m_{i=1}[(1-y^{(i)})\\frac{1}{(1-h(x^{(i)})}\\frac{\\partial(1-h(x^{(i)})}{\\partial{\\theta_j}}]$\n",
    "\n",
    "$=\\frac{1}{m}\\sum^m_{i=1}[y^{(i)}\\frac{1}{h(x^{(i)})}h(x^{(i)})(1-h(x^{(i)})x^{(i)}_j]+\\sum^m_{i=1}[(1-y^{(i)})\\frac{1}{(1-h(x^{(i)})}(-h(x^{(i)}))(1-h(x^{(i)}))x^{(i)}_j]$\n",
    "\n",
    "$=-\\frac{1}{m}\\sum^m_{i=1}[y^{(i)}-h(x^{(i)})]x^i_j$ $=\\frac{1}{m}X^T[h(x)-y]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, alpha, n_iters):\n",
    "    costs, m, n = [], len(x), len(theta)\n",
    "    new_theta = theta\n",
    "    for k in range(n_iters):\n",
    "        for j in range(n):\n",
    "            sums = 0\n",
    "            for i in range(m):\n",
    "                sums += (y[i] - h(theta[j], x[i][j])) * x[i][j]\n",
    "            partial = (-1/m) * sums\n",
    "            new_theta[j] = new_theta[j] - alpha * partial\n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we're not going to use numpy in this notebook, we need to define 2 functions to help us find mean and standard deviation from a row-based 2d array 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean(x, column):\n",
    "    m = len(x[0])\n",
    "    sums = 0\n",
    "    for i in range(m):\n",
    "        sums += x[i][column]\n",
    "    return sums/m\n",
    "\n",
    "def find_std(x, column):\n",
    "    mu = find_mean(x, column)\n",
    "    std, m = 0, len(x[0])\n",
    "    for i in range(m):\n",
    "        std += (x[i][column] - mu) ** 2\n",
    "    print(1 / m * std)\n",
    "    return (1 / m * std) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(x):\n",
    "    m, n = len(x), len(x[0])\n",
    "    standarised_x = [[0 for j in range(len(x[0]))] for i in range(len(x))]\n",
    "    for j in range(n):      # iterate through columns\n",
    "        mu, sigma = find_mean(x, j), find_std(x, j)\n",
    "        for i in range(m):  # iterate through rows\n",
    "            standarised_x[i][j] = (x[i][j] - mu) / sigma\n",
    "    return standarised_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destandardization(x, theta):\n",
    "    for j in range(len(theta)):\n",
    "        if j == 0:\n",
    "            theta[j] = 0\n",
    "        else:\n",
    "            sigma = find_std(x, j)\n",
    "            theta[j] = theta[j] / sigma\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "with open(\"./score_logisticregression.txt\", 'r') as f:\n",
    "    contents = f.readlines()\n",
    "    for content in contents:\n",
    "        xx.append(content.split('\\t'))\n",
    "x = [[0 for j in range(len(xx[0])-1)] for i in range(len(xx))]\n",
    "y = [0 for i in range(len(xx))]\n",
    "for i in range(len(xx)):\n",
    "    for j in range(len(xx[0])):\n",
    "        if j == 2:\n",
    "            if 'passed' in xx[i][j]: y[i] = 1\n",
    "        else:\n",
    "            x[i][j] = int(xx[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.25\n",
      "576.0\n",
      "0.6816034141137021\n",
      "1.1392746913580247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0.5178226912239681, 1.1773943070882966]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standarized_x = standardization(x)\n",
    "# append one column as intercept:\n",
    "for i in range(len(standarized_x)):\n",
    "    standarized_x[i] = [1] + standarized_x[i]\n",
    "theta = [1 for _ in range(len(standarized_x[0]))]\n",
    "\n",
    "theta = gradient_descent(standarized_x, y, theta, alpha=0.003, n_iters=3000)\n",
    "theta = destandardization(standarized_x, theta)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing test below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = x, y\n",
    "clf = LogisticRegression(random_state=0).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.19169748, 0.19885119]]), array([-15.67387703]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "theta_trained = gradient_descent(standarized_x, y, theta, alpha=0.003, n_iters=3000)\n",
    "\n",
    "for i in range(len(standarized_x)):\n",
    "    curr_y = 0\n",
    "    for j in range(len(standarized_x[0])):\n",
    "        curr_y += h(theta_trained[j], standarized_x[i][j])\n",
    "    \n",
    "    if curr_y > 0.5: y_pred.append(1)\n",
    "    else: y_pred.append(0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y[i]:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-f39c6d82e83d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-f39c6d82e83d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    plt.plot(standarized_x_np[])\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "standarized_x_np = np.array(standarized_x)\n",
    "plt.plot(standarized_x_np[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
